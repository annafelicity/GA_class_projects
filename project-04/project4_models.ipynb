{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classifying Housing Prices\n",
    "\n",
    "Objective: Given a data set about housing/property prices, create a model that can predict whether a house/property will have a low or high price\n",
    "\n",
    "#### How did I operationalize my target?\n",
    "The original data set contained a price column. I ran some basic descriptive statistics and decided that the median price would serve as a reasonable mid-point for dividing up housing prices into a low and high category. From there, I created an \"is_high\" column that served as the target by assigning zero to those rows with a price < $273,500 and 1 to those equal to or over that figure.\n",
    "(Note: see Jupyter notebook project4_data for a more detailed look at this data transformation process.)\n",
    "\n",
    "#### How did I choose which data to include?\n",
    "Using a combination of techniques (see Jupyter notebook project4_eda) I determined that there were a lot of variables that didn't have particularly high correlation with directly predicting the housing price. Baths were the most highly correlated variable in any direction (in this case positive) followed by square feet (both of which make clear sense); surprisingly beds were only sightly correlated. \n",
    "\n",
    "A few clear features that had impact were that zip code and the status of house were somwhat negatively correlated with price. (Although note below, when I modeled, zip code didn't have any effect--I may have done something wrong there.) New construction--something typically highly coveted in today's housing market was somewhat more highly correlated with higher price. Condos were also highly correlated with higher price. Auction and foreclosure properties were both negatively correlated with price, as would be expected as those almost always sell under market price. Most other variables appeared to have less to little impact.\n",
    "\n",
    "When looking at a Seaborn heatmap of the values columns of all the transformed data, there was very little overlap between them with the exception of beds, baths, and square feet being correlated with each other.\n",
    "\n",
    "I tried three basic models. Model 1 was beds, baths, and square feet. Model 2 was those plus zip code (again, I think I need to redo this one). Model 3 was the number of beds, number of baths, square footage, dummy variables for all of the housing types, and zip code\n",
    "\n",
    "Although I didn't try this, some additional improvement in the model might have come from doing something with the address data--trying to further break down each zip code into smaller neighborhoods.\n",
    "\n",
    "#### How did I transform my data?\n",
    "First I dropped all the null value rows. Most of these were in housing-type categories that had small numbers of properties, and the remaining categories covered all the relevant types of properties (e.g. one that got dropped was \"coming soon\" which obviously doesn't have complete data since it's not final yet and only had 15 rows in the dataset). Due to dropping rows with empty values, the number of housing types dropped from 15 to 12.\n",
    "Then some columns needed to be transformed into numbers from strings (note: I'm sure there's a combination way to do all the .replace lines, but I couldn't figure it out).\n",
    "\n",
    "The \"bed_bath\" column needed to be split on the \" • \" divider and then cleaned quite a bit--dropping the non-number parts of the values, converting things like \"--\" to 0, and converting the word \"studio\" to 0.\n",
    "Then dummy columns needed to be made for all the categorical variables (remembering to drop one).\n",
    "\n",
    "The only column from the original data set that was still relevant as unchanged was the zip code one. Although now with further thought, I think this also needs to be turned into categorical variables with get_dummies.\n",
    "\n",
    "Then I created a few different dataframes to use as matrices for modeling: a df_bbsplit one that had the beds, baths, and square feet, one that merged bbsplit with the zip code, and one that had everything including the categorical variables.\n",
    "\n",
    "\n",
    "#### What are my findings?\n",
    "\n",
    "One of my interesting findings is that just the beds, baths, and square feet of a property are reasonably predictive of the price. That scored at .75 with a non-cross-validated model and using various tools, this was fairly consistent (e.g. cross_val_score gave me 0.79724656, 0.73763306,  0.70444584; all the iterations in GridSearchCV gave me scores in the .70s with a best estimator model score of .76 using l2 regression and a penalty of C=0.1.)\n",
    "\n",
    "Since the Seaborn heatmap and correlating the columns with one another showed a high correlation between beds, baths, and square feet (as would be expected), I also tried a model that used just beds, but that turned out much worse. And then because baths had somewhat of a correlation with the target, I tried just baths. This scored at .66, so that was interesting that just the baths were fairly predictive of property price.\n",
    "\n",
    "Adding in the zip codes, surprisingly, didn't change anything (I'm actually wondering if something's wrong because in the correlation eda, zip code was negatively correlated with the target by -0.29 so it's really strange that the score isn't changing at all..I think I need to do a dummy variables treatment on zip codes.)\n",
    "\n",
    "Using the categorical values improved the model a small amount from .75 to .78 on the regular regression and to .78 with the best estimator model.\n",
    "\n",
    "#### How strong do I think my model is?\n",
    "\n",
    "Pretty strong. See above for scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>bed_bath</th>\n",
       "      <th>more_info</th>\n",
       "      <th>price</th>\n",
       "      <th>status</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360 E Randolph St # 601-602, Chicago, IL</td>\n",
       "      <td>3 bds · 4 ba · 2,700 sqft</td>\n",
       "      <td>http://www.zillow.com/homedetails/360-E-Randol...</td>\n",
       "      <td>$1,299,000</td>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 E Randolph St UNIT 1006, Chicago, IL</td>\n",
       "      <td>1 bd · 1 ba · 850 sqft</td>\n",
       "      <td>http://www.zillow.com/homedetails/8-E-Randolph...</td>\n",
       "      <td>$324,900</td>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340 E Randolph St APT 704, Chicago, IL</td>\n",
       "      <td>2 bds · 3 ba · 1,902 sqft</td>\n",
       "      <td>http://www.zillow.com/homedetails/340-E-Randol...</td>\n",
       "      <td>$1,099,000</td>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420 E Waterside Dr UNIT 310, Chicago, IL</td>\n",
       "      <td>2 bds · 3 ba · 1,500 sqft</td>\n",
       "      <td>http://www.zillow.com/homedetails/420-E-Waters...</td>\n",
       "      <td>$567,770</td>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>60601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    address                   bed_bath  \\\n",
       "0  360 E Randolph St # 601-602, Chicago, IL  3 bds · 4 ba · 2,700 sqft   \n",
       "1    8 E Randolph St UNIT 1006, Chicago, IL     1 bd · 1 ba · 850 sqft   \n",
       "2                                       NaN                        NaN   \n",
       "3    340 E Randolph St APT 704, Chicago, IL  2 bds · 3 ba · 1,902 sqft   \n",
       "4  420 E Waterside Dr UNIT 310, Chicago, IL  2 bds · 3 ba · 1,500 sqft   \n",
       "\n",
       "                                           more_info       price  \\\n",
       "0  http://www.zillow.com/homedetails/360-E-Randol...  $1,299,000   \n",
       "1  http://www.zillow.com/homedetails/8-E-Randolph...    $324,900   \n",
       "2                                                NaN         NaN   \n",
       "3  http://www.zillow.com/homedetails/340-E-Randol...  $1,099,000   \n",
       "4  http://www.zillow.com/homedetails/420-E-Waters...    $567,770   \n",
       "\n",
       "           status  zip_code  \n",
       "0  Condo For Sale     60601  \n",
       "1  Condo For Sale     60601  \n",
       "2             NaN     60601  \n",
       "3  Condo For Sale     60601  \n",
       "4  Condo For Sale     60601  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drops rows with NaN values\n",
    "df = df.dropna()\n",
    "#gets rid of $ and ,, in the prices\n",
    "df[\"price\"] = df[\"price\"].str.replace(\"$\", \"\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(\",\", \"\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(\"M\", \"000000\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(\"K\", \"000\")\n",
    "df[\"price\"] = df[\"price\"].str.replace(\"+\", \"\")\n",
    "#change values to floats from strings\n",
    "df[\"price\"] = df[\"price\"].apply(float)\n",
    "#drop the 134 rows that have a funky format in bed_bath\n",
    "#(found using the following code: df.loc[df[\"bed_bath\"].str.contains(\"lot\") == True].shape)\n",
    "df = df.loc[df[\"bed_bath\"].str.contains(\"lot\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turn \"--\" into 0 in bed_bath and turn \"Studio\" into \"0 bds\"\n",
    "df[\"bed_bath\"] = df[\"bed_bath\"].str.replace(\"--\", \"0\")\n",
    "df[\"bed_bath\"] = df[\"bed_bath\"].str.replace(\"Studio\", \"0 bds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#assigning the \"bed_bath\" splits to a new df (that I can join to the original df later)\n",
    "df_bbsplit = pd.DataFrame(df[\"bed_bath\"].str.split(\" · \").tolist(), columns = [\"beds\", \"baths\", \"sqft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean the data in the new df columns to change to ints\n",
    "df_bbsplit[\"sqft\"] = df_bbsplit[\"sqft\"].str.replace(\",\",'')\n",
    "df_bbsplit[\"sqft\"] = df_bbsplit[\"sqft\"].str.replace(\"sqft\",\"\")\n",
    "df_bbsplit[\"sqft\"] = df_bbsplit[\"sqft\"].str.replace(\"+\",\"\")\n",
    "df_bbsplit[\"beds\"] = df_bbsplit[\"beds\"].str.replace(\" bds\",\"\")\n",
    "df_bbsplit[\"beds\"] = df_bbsplit[\"beds\"].str.replace(\" bd\",\"\")\n",
    "df_bbsplit[\"baths\"] = df_bbsplit[\"baths\"].str.replace(\" ba\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to ints\n",
    "df_bbsplit[\"sqft\"] = pd.to_numeric(df_bbsplit[\"sqft\"])\n",
    "df_bbsplit[\"beds\"] = pd.to_numeric(df_bbsplit[\"beds\"])\n",
    "df_bbsplit[\"baths\"] = pd.to_numeric(df_bbsplit[\"baths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      beds  baths  sqft\n",
       "4787     4    3.0  1775\n",
       "4788     4    2.0   910\n",
       "4789     8    3.0     0\n",
       "4790     3    1.0  1191\n",
       "4791     4    2.0  1181"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbsplit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get dummies for status using the built-in n -1 thing.\n",
    "df_status_dummies = pd.get_dummies(df[\"status\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fixes index problem with status dummies\n",
    "#index was using the numbers from the original dataset before dropped rows\n",
    "df_status_dummies.index = range(len(df_status_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create operationalized target-- >= to median (273500.0) is high, < is low\n",
    "df[\"is_high\"] = df[\"price\"].apply(lambda x: 1 if x >=273500.0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create target\n",
    "target = df[\"is_high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create version of original df with only relevant columns to join others to\n",
    "df_zip = df[[\"zip_code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fix index to conform with bbsplit\n",
    "df_zip.index = range(len(df_zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#join together first two dfs\n",
    "housing_data_intm = pd.merge(df_zip, df_bbsplit, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4792, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data_intm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_data = pd.merge(housing_data_intm, df_status_dummies, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>Auction</th>\n",
       "      <th>Co-op For Sale</th>\n",
       "      <th>Coming Soon</th>\n",
       "      <th>Condo For Sale</th>\n",
       "      <th>For Sale by Owner</th>\n",
       "      <th>Foreclosure</th>\n",
       "      <th>House For Sale</th>\n",
       "      <th>Lot/Land For Sale</th>\n",
       "      <th>Make Me Move®</th>\n",
       "      <th>New Construction</th>\n",
       "      <th>Townhouse For Sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>60827</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>60827</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>60827</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>60827</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>60827</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_code  beds  baths  sqft  Auction  Co-op For Sale  Coming Soon  \\\n",
       "4787     60827     4    3.0  1775        0               0            0   \n",
       "4788     60827     4    2.0   910        0               0            0   \n",
       "4789     60827     8    3.0     0        0               0            0   \n",
       "4790     60827     3    1.0  1191        0               0            0   \n",
       "4791     60827     4    2.0  1181        0               0            0   \n",
       "\n",
       "      Condo For Sale  For Sale by Owner  Foreclosure  House For Sale  \\\n",
       "4787               0                  0            0               1   \n",
       "4788               0                  0            0               1   \n",
       "4789               0                  0            0               0   \n",
       "4790               0                  0            0               1   \n",
       "4791               0                  0            0               1   \n",
       "\n",
       "      Lot/Land For Sale  Make Me Move®  New Construction  Townhouse For Sale  \n",
       "4787                  0              0                 0                   0  \n",
       "4788                  0              0                 0                   0  \n",
       "4789                  0              0                 0                   0  \n",
       "4790                  0              0                 0                   0  \n",
       "4791                  0              0                 0                   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4792, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first model with just the bed/bath/sqft values as a matrix\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(df_bbsplit, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75772120200333892"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(df_bbsplit, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying with the intermediate merge of zip and bb_split\n",
    "log_reg_2 = LogisticRegression()\n",
    "log_reg_2.fit(housing_data_intm, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75813856427378967"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_2.score(housing_data_intm, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maybe try one just with beds only...hmmmmm\n",
    "log_reg_beds = LogisticRegression()\n",
    "log_reg_beds.fit(df_bbsplit[\"beds\"].values.reshape(-1, 1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53547579298831383"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_beds.score(df_bbsplit[\"beds\"].values.reshape(-1, 1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baths had a high correlation with the target, how does that work on its own?\n",
    "log_reg_baths = LogisticRegression()\n",
    "log_reg_baths.fit(df_bbsplit[\"baths\"].values.reshape(-1, 1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66402337228714525"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_baths.score(df_bbsplit[\"baths\"].values.reshape(-1, 1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try a model with everything: beds, baths, sqft, zip code, categories\n",
    "log_reg_3 = LogisticRegression()\n",
    "log_reg_3.fit(housing_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77900667779632726"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_3.score(housing_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Crossvalidation, Testing, Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: log_reg (uses beds, baths, sqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79724656,  0.75516594,  0.7100814 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_reg, df_bbsplit, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.796621, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.753287, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.710708, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.799124, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.755792, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.712586, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.795995, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.752661, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.708203, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.797247, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1.0, penalty=l2, score=0.755166, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.710081, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.795995, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.752035, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.708203, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.797247, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.755166, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.710081, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'penalty': ['l1', 'l2'],\n",
    "                   'C': [0.1, 1.0, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(log_reg, hyperparameters, verbose=10)\n",
    "\n",
    "grid_search.fit(df_bbsplit, target)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76168614357262099"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(df_bbsplit, target)\n",
    "grid_search.best_estimator_.score(df_bbsplit, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: log_reg_2 (beds, baths, sqft, zip code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79599499,  0.74452098,  0.70757671])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_reg, housing_data_intm, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.796621, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.752661, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.710081, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.796621, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.741390, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.709455, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.795995, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1.0, penalty=l1, score=0.753287, total=   0.1s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.708203, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.795995, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.744521, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.707577, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.795369, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=10, penalty=l1, score=0.752035, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.708203, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.795995, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.744521, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.707577, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'penalty': ['l1', 'l2'],\n",
    "                   'C': [0.1, 1.0, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(log_reg, hyperparameters, verbose=10)\n",
    "\n",
    "grid_search.fit(housing_data_intm, target)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75939065108514192"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(housing_data_intm, target)\n",
    "grid_search.best_estimator_.score(housing_data_intm, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: log_reg_3 (beds, baths, sqft, zip code, and categorical variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80851064,  0.76393237,  0.72197871])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log_reg, housing_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.812891, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.780839, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l1, score=0.723231, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.808511, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.764559, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................ C=0.1, penalty=l2, score=0.718848, total=   0.0s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1.0, penalty=l1, score=0.821652, total=   0.1s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.785848, total=   0.1s\n",
      "[CV] C=1.0, penalty=l1 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l1, score=0.726362, total=   0.1s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.808511, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n",
      "[CV] ................ C=1.0, penalty=l2, score=0.763932, total=   0.0s\n",
      "[CV] C=1.0, penalty=l2 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1.0, penalty=l2, score=0.721979, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.821652, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.785848, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................. C=10, penalty=l1, score=0.733876, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.808511, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.763932, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................. C=10, penalty=l2, score=0.703193, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'penalty': ['l1', 'l2'],\n",
    "                   'C': [0.1, 1.0, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(log_reg, hyperparameters, verbose=10)\n",
    "\n",
    "grid_search.fit(housing_data, target)\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78171953255425708"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(housing_data, target)\n",
    "grid_search.best_estimator_.score(housing_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
