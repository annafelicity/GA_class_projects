{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This data comes from the City of Chicago and is for all public schools in Chicago. Your task is to classify schools into probationary status (probation = 1) and non-probationary status (probation = 0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are my pipeline steps:\n",
    "\n",
    "1) import all my libraries I need\n",
    "\n",
    "2) import train and test data\n",
    "\n",
    "3) operationalize y (y = \"probation\")\n",
    "\n",
    "4) write all my definitions\n",
    "\n",
    "5) clean/transform data column by column for x\n",
    "    (make sure each column has a deal with nan function)\n",
    "    \n",
    "6) create x with make_union\n",
    "\n",
    "7) fit train to a model (try KNN and LogReg--remember LogReg needs one dummy dropped from each set of dummies)\n",
    "\n",
    "8) score and crossvalidate model\n",
    "\n",
    "9) if good, predict y hat with test data\n",
    "\n",
    "10) export predictions to csv to upload to Kaggle\n",
    "\n",
    "Note: when I am trying to figure out a good model I can use the train/test split on the training data to check it and also the cross validation techniques and other tests like GridSearchCV (to get the best_estimator_ figures). But those won't go in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1) import stuff (can prob get rid of seaborn and matplotlib for final v)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, FunctionTransformer, LabelBinarizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set view stuff (only needed for draft in Jupyter notebook)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2) import train and test data\n",
    "school_train = pd.read_csv('school_data_training.csv')\n",
    "school_test = pd.read_csv('school_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3) operationalize y (y = \"probation\")\n",
    "target_train = school_train[\"probation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4) write all my definitions\n",
    "#extract column\n",
    "def col_extractor(df, col_name=\"column_name\"):\n",
    "    return df[col_name]\n",
    "#I'm going to get back to this...I think it should work if I do some sort of nesting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_student_col(df):\n",
    "    return df[\"Average Student Attendance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def healthy_schools_col(df):\n",
    "    return df[\"Healthy Schools Certified?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misconduct_col(df):\n",
    "    return df[\"Rate of Misconducts (per 100 students) \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_teacher_col(df):\n",
    "    return df[\"Average Teacher Attendance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iep_col(df):\n",
    "    return df[\"Individualized Education Program Compliance Rate \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ward_col(df):\n",
    "    return df[\"Ward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def police_d_col(df):\n",
    "    return df[\"Police District\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip percentage signs\n",
    "def strip_percent(column):\n",
    "    column = column.str.replace(\"%\", \"\")\n",
    "    column = column.apply(float)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_array(column):\n",
    "    return column.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5) make pipelines to clean/transform data column by column for x \n",
    "#(in the real world make sure each column has a deal with nan function\n",
    "#but not necessary here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_stud_pipe = make_pipeline(FunctionTransformer(avg_student_col, validate=False),\n",
    "                         FunctionTransformer(strip_percent, validate=False),\n",
    "                             FunctionTransformer(return_array, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer-1', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function avg_student_col at 0x111283048>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=False, validate=False)), ('functiontransformer-2', FunctionTransformer(accept_sparse=False,\n",
       "        ...54950>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=False, validate=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_stud_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 96.2],\n",
       "       [ 96.6],\n",
       "       [ 91.3],\n",
       "       [ 84.8],\n",
       "       [ 91. ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_stud_pipe.fit_transform(school_train)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_teach_pipe = make_pipeline(FunctionTransformer(avg_teacher_col, validate=False),\n",
    "                         FunctionTransformer(strip_percent, validate=False),\n",
    "                         FunctionTransformer(return_array, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miscon_pipe = make_pipeline(FunctionTransformer(misconduct_col, validate=False),\n",
    "                         FunctionTransformer(return_array, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iep_pipe = make_pipeline(FunctionTransformer(iep_col, validate=False),\n",
    "                         FunctionTransformer(strip_percent, validate=False),\n",
    "                         FunctionTransformer(return_array, validate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "police_pipe = make_pipeline(FunctionTransformer(police_d_col, validate=False),\n",
    "                         FunctionTransformer(return_array, validate=False),\n",
    "                         LabelBinarizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ward_pipe = make_pipeline(FunctionTransformer(ward_col, validate=False),\n",
    "                         FunctionTransformer(return_array, validate=False),\n",
    "                         LabelBinarizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ward_pipe.fit_transform(school_train)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6) create x with make_union\n",
    "union = make_union(avg_stud_pipe, avg_teach_pipe, iep_pipe, miscon_pipe, police_pipe, ward_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  96.2,   97.4,   99. , ...,    0. ,    0. ,    0. ],\n",
       "       [  96.6,   96.3,  100. , ...,    0. ,    0. ,    0. ],\n",
       "       [  91.3,   95. ,  100. , ...,    0. ,    0. ,    0. ],\n",
       "       ..., \n",
       "       [  93.3,   94.1,  100. , ...,    0. ,    0. ,    0. ],\n",
       "       [  96.5,   96.3,  100. , ...,    0. ,    0. ,    0. ],\n",
       "       [  92. ,   94.4,  100. , ...,    0. ,    0. ,    0. ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union.fit_transform(school_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65150232,  0.28657462,  0.03859543, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645],\n",
       "       [ 0.71986424,  0.15215699,  0.46928295, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645],\n",
       "       [-0.18593122, -0.00670022,  0.46928295, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645],\n",
       "       ..., \n",
       "       [ 0.15587839, -0.11667829,  0.46928295, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645],\n",
       "       [ 0.70277376,  0.15215699,  0.46928295, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645],\n",
       "       [-0.06629785, -0.08001893,  0.46928295, ..., -0.09877296,\n",
       "        -0.09877296, -0.11056645]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then add standard scaler for knn\n",
    "final_pipe = make_pipeline(union, StandardScaler())\n",
    "final_pipe.fit_transform(school_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7) fit train to a model \n",
    "#(try KNN and LogReg--remember LogReg needs one dummy \n",
    "#dropped from each set of dummies)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(final_pipe.fit_transform(school_train), target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8) score and crossvalidate model\n",
    "#Note: this is not part of the final pipeline--just for finding best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72463768115942029"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(union.fit_transform(school_train), target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9) if good, predict y hat with test data\n",
    "#Note: this will be part of the final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict the model with the test dataset\n",
    "predictions = knn.predict(final_pipe.transform(school_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10) export predictions to csv to upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for now use R's solution:\n",
    "def evaluation_transformation(dataset, predictions):\n",
    "    dataset = dataset.join(pd.DataFrame(predictions, columns=['Prediction']))\n",
    "    dataset[['Id', 'Prediction']].to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation_transformation(school_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
