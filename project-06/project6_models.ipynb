{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1)import all the stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2)import data scraped from web and saved to csv\n",
    "movie_data = pd.read_csv(\"IMDBTop250.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3)operationalize y into two categories: \"amazing\"=1 and \"good\"=0\n",
    "#this is the target variable\n",
    "is_amazing = movie_data[\"imdbRating\"].apply(lambda x: 0 if x <= np.median(movie_data[\"imdbRating\"]) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4)make X (doing this as a pipeline in case I want to scrape more data later)\n",
    "\n",
    "#4a)write all my definitions\n",
    "#column extractors:\n",
    "def actors_col(df):\n",
    "    return df[\"Actors\"]\n",
    "\n",
    "def director_col(df):\n",
    "    return df[\"Director\"]\n",
    "\n",
    "def genre_col(df):\n",
    "    return df[\"Genre\"]\n",
    "\n",
    "def plot_col(df):\n",
    "    return df[\"Plot\"]\n",
    "\n",
    "def rated_col(df):\n",
    "    return df[\"Rated\"]\n",
    "\n",
    "def runtime_col(df):\n",
    "    return df[\"Runtime\"]\n",
    "\n",
    "def title_col(df):\n",
    "    return df[\"Title\"]\n",
    "\n",
    "def year_col(df):\n",
    "    return df[\"Year\"].values.reshape(-1, 1)\n",
    "\n",
    "#clean runtime col\n",
    "def runtime_fix(df):\n",
    "    df = df.str.replace(\" min\",\"\")\n",
    "    df = df.apply(int)\n",
    "    return df.values.reshape(-1, 1)\n",
    "\n",
    "#todense for CountVectorizer pipes\n",
    "def dense(sparse):\n",
    "    return sparse.todense()\n",
    "\n",
    "#returns array when needed\n",
    "def return_array(column):\n",
    "    return column.values.reshape(-1, 1)\n",
    "\n",
    "#fill nan for rated col\n",
    "def not_rated(column):\n",
    "    column.fillna(\"NOT RATED\", inplace=True)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5b) make pipelines:\n",
    "actors_pipe = make_pipeline(FunctionTransformer(actors_col, validate=False),\n",
    "                         CountVectorizer(ngram_range=(2, 3), min_df=2),\n",
    "                         FunctionTransformer(dense, validate=False))\n",
    "\n",
    "director_pipe = make_pipeline(FunctionTransformer(director_col, validate=False),\n",
    "                              LabelBinarizer())\n",
    "\n",
    "genre_pipe = make_pipeline(FunctionTransformer(genre_col, validate=False), \n",
    "                           CountVectorizer())\n",
    "\n",
    "rated_pipe = make_pipeline(FunctionTransformer(rated_col, validate=False),\n",
    "                           FunctionTransformer(not_rated, validate=False),\n",
    "                           LabelBinarizer())\n",
    "\n",
    "runtime_pipe = make_pipeline(FunctionTransformer(runtime_col, validate=False),\n",
    "                             FunctionTransformer(runtime_fix, validate=False))\n",
    "\n",
    "year_pipe = make_pipeline(FunctionTransformer(year_col, validate=False), LabelBinarizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4c) make feature union:\n",
    "# union = make_union(actors_pipe, director_pipe, genre_pipe, rated_pipe, runtime_pipe, year_pipe)\n",
    "union = make_union(actors_pipe, director_pipe, genre_pipe, runtime_pipe, year_pipe, rated_pipe)\n",
    "X = union.fit_transform(movie_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642857142857\n",
      "[[48  4]\n",
      " [26  6]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.92      0.76        52\n",
      "          1       0.60      0.19      0.29        32\n",
      "\n",
      "avg / total       0.63      0.64      0.58        84\n",
      "\n",
      "0.571428571429\n",
      "[[46  6]\n",
      " [30  2]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.88      0.72        52\n",
      "          1       0.25      0.06      0.10        32\n",
      "\n",
      "avg / total       0.47      0.57      0.48        84\n",
      "\n",
      "0.609756097561\n",
      "[[46  5]\n",
      " [27  4]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.90      0.74        51\n",
      "          1       0.44      0.13      0.20        31\n",
      "\n",
      "avg / total       0.56      0.61      0.54        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfolds = StratifiedKFold()\n",
    "for train, test in kfolds.split(X, is_amazing):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X[train], is_amazing[train])\n",
    "    print (rf.score(X[test], is_amazing[test]))\n",
    "    actual_values = is_amazing[test]\n",
    "    predicted_values = rf.predict(X[test])\n",
    "    #add confusion matrices and classification reports\n",
    "    print(confusion_matrix(actual_values, predicted_values))\n",
    "    print(classification_report(actual_values, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852\n",
      "[[149   6]\n",
      " [ 31  64]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.96      0.89       155\n",
      "          1       0.91      0.67      0.78        95\n",
      "\n",
      "avg / total       0.86      0.85      0.85       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_fd = RandomForestClassifier()\n",
    "rf_fd.fit(X, is_amazing)\n",
    "print (rf.score(X, is_amazing))\n",
    "actual_values_fd = is_amazing\n",
    "predicted_values_fd = rf.predict(X)\n",
    "print(confusion_matrix(actual_values_fd, predicted_values_fd))\n",
    "print(classification_report(actual_values_fd, predicted_values_fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.076488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.030796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.019347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.014570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.014268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.013325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.013044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.012470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.012447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.011717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.011182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.010437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.010325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.010196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.009384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.009220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.009149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.009015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "344  0.076488\n",
       "403  0.030796\n",
       "408  0.019347\n",
       "181  0.014570\n",
       "429  0.014268\n",
       "404  0.013325\n",
       "298  0.013044\n",
       "327  0.012470\n",
       "350  0.012447\n",
       "328  0.011717\n",
       "415  0.011182\n",
       "430  0.010968\n",
       "326  0.010437\n",
       "227  0.010325\n",
       "433  0.010196\n",
       "342  0.009893\n",
       "406  0.009384\n",
       "50   0.009220\n",
       "256  0.009149\n",
       "200  0.009015"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay so I think the feature_importances is kind of useless here\n",
    "#because the columns don't have names (remember need to add .todense() to retrieve all)\n",
    "#I either need to figure out what data corresponds with what column\n",
    "#or I need to redo this as a regular df\n",
    "# and I could do what Richard did today with the classifiers and name each dummy column\n",
    "\n",
    "feature_importances = pd.DataFrame(rf_fd.feature_importances_).sort_values(0, ascending=False)\n",
    "feature_importances.head(20)\n",
    "\n",
    "#see this code for a way to get the feature names (from )\n",
    "#feature_importances = pd.DataFrame(dt.feature_importances_,\n",
    "#                                   index = X.columns,\n",
    "#                                    columns=['importance']).sort_values('importance',\n",
    "#                                                                        ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
